/*
* This header is generated by classdump-dyld 1.0
* on Wednesday, May 18, 2016 at 11:49:22 PM Eastern Daylight Time
* Operating System: Version 9.0.2 (Build 13A452)
* Image Source: /var/mobile/Containers/Bundle/Application/FFD4619E-59E7-49B9-AD90-0E28F5807C56/YouTube.app/YouTube
* classdump-dyld is licensed under GPLv3, Copyright Â© 2013-2016 by Elias Limneos.
*/

#import <YouTube/YouTube-Structs.h>
#import <YouTube/GPUImageOutput.h>
#import <libobjc.A.dylib/AVCaptureVideoDataOutputSampleBufferDelegate.h>
#import <YouTube/AVCaptureAudioDataOutputSampleBufferDelegate.h>

@protocol OS_dispatch_semaphore, GPUImageVideoCameraDelegate, OS_dispatch_queue;
@class AVCaptureSession, AVCaptureDevice, AVCaptureDeviceInput, AVCaptureVideoDataOutput, NSObject, AVCaptureAudioDataOutput, NSDate, GLProgram, NSString;

@interface GPUImageVideoCamera : GPUImageOutput <AVCaptureVideoDataOutputSampleBufferDelegate, AVCaptureAudioDataOutputSampleBufferDelegate> {

	unsigned numberOfFramesCaptured;
	float totalFrameTimeDuringCapture;
	AVCaptureSession* _captureSession;
	AVCaptureDevice* _inputCamera;
	AVCaptureDevice* _microphone;
	AVCaptureDeviceInput* videoInput;
	AVCaptureVideoDataOutput* videoOutput;
	char capturePaused;
	int outputRotation;
	int internalRotation;
	NSObject*<OS_dispatch_semaphore> frameRenderingSemaphore;
	char captureAsYUV;
	unsigned luminanceTexture;
	unsigned chrominanceTexture;
	id<GPUImageVideoCameraDelegate> _delegate;
	AVCaptureDeviceInput* audioInput;
	AVCaptureAudioDataOutput* audioOutput;
	NSDate* startingCaptureTime;
	NSObject*<OS_dispatch_queue> cameraProcessingQueue;
	NSObject*<OS_dispatch_queue> audioProcessingQueue;
	GLProgram* yuvConversionProgram;
	int yuvConversionPositionAttribute;
	int yuvConversionTextureCoordinateAttribute;
	int yuvConversionLuminanceTextureUniform;
	int yuvConversionChrominanceTextureUniform;
	int yuvConversionMatrixUniform;
	const float* _preferredConversion;
	char isFullYUVRange;
	int imageBufferWidth;
	int imageBufferHeight;
	char addedAudioInputsDueToEncodingTarget;
	char _runBenchmark;
	char _horizontallyMirrorFrontFacingCamera;
	char _horizontallyMirrorRearFacingCamera;
	NSString* _captureSessionPreset;
	int _outputImageOrientation;
	int _frameRate;

}

@property (nonatomic,retain,readonly) AVCaptureSession * captureSession;                           //@synthesize captureSession=_captureSession - In the implementation block
@property (nonatomic,copy) NSString * captureSessionPreset;                                        //@synthesize captureSessionPreset=_captureSessionPreset - In the implementation block
@property (assign) int frameRate;                                                                  //@synthesize frameRate=_frameRate - In the implementation block
@property (getter=isFrontFacingCameraPresent,readonly) char frontFacingCameraPresent; 
@property (getter=isBackFacingCameraPresent,readonly) char backFacingCameraPresent; 
@property (assign,nonatomic) char runBenchmark;                                                    //@synthesize runBenchmark=_runBenchmark - In the implementation block
@property (readonly) AVCaptureDevice * inputCamera;                                                //@synthesize inputCamera=_inputCamera - In the implementation block
@property (assign,nonatomic) int outputImageOrientation;                                           //@synthesize outputImageOrientation=_outputImageOrientation - In the implementation block
@property (assign,nonatomic) char horizontallyMirrorFrontFacingCamera;                             //@synthesize horizontallyMirrorFrontFacingCamera=_horizontallyMirrorFrontFacingCamera - In the implementation block
@property (assign,nonatomic) char horizontallyMirrorRearFacingCamera;                              //@synthesize horizontallyMirrorRearFacingCamera=_horizontallyMirrorRearFacingCamera - In the implementation block
@property (assign,nonatomic) id<GPUImageVideoCameraDelegate> delegate;                             //@synthesize delegate=_delegate - In the implementation block
@property (readonly) unsigned hash; 
@property (readonly) Class superclass; 
@property (copy,readonly) NSString * description; 
@property (copy,readonly) NSString * debugDescription; 
+(char)isFrontFacingCameraPresent;
+(char)isBackFacingCameraPresent;
-(void)addTarget:(id)arg1 atTextureLocation:(int)arg2 ;
-(void)convertYUVToRGBOutput;
-(char)runBenchmark;
-(void)setRunBenchmark:(char)arg1 ;
-(id)framebufferForOutput;
-(void)setAudioEncodingTarget:(id)arg1 ;
-(id)initWithSessionPreset:(id)arg1 cameraPosition:(int)arg2 ;
-(void)removeInputsAndOutputs;
-(void)stopCameraCapture;
-(char)isFrontFacingCameraPresent;
-(void)setOutputImageOrientation:(int)arg1 ;
-(char)isBackFacingCameraPresent;
-(void)updateTargetsForVideoCameraUsingCacheTextureAtWidth:(int)arg1 height:(int)arg2 time:(SCD_Struct_YT44)arg3 ;
-(float)averageFrameDurationDuringCapture;
-(void)processAudioSampleBuffer:(opaqueCMSampleBufferRef)arg1 ;
-(void)processVideoSampleBuffer:(opaqueCMSampleBufferRef)arg1 ;
-(char)addAudioInputsAndOutputs;
-(char)removeAudioInputsAndOutputs;
-(void)updateOrientationSendToTargets;
-(void)startCameraCapture;
-(void)pauseCameraCapture;
-(void)resumeCameraCapture;
-(void)rotateCamera;
-(void)setCaptureSessionPreset:(NSString *)arg1 ;
-(id)videoCaptureConnection;
-(void)resetBenchmarkAverage;
-(void)setHorizontallyMirrorFrontFacingCamera:(char)arg1 ;
-(void)setHorizontallyMirrorRearFacingCamera:(char)arg1 ;
-(NSString *)captureSessionPreset;
-(AVCaptureDevice *)inputCamera;
-(int)outputImageOrientation;
-(char)horizontallyMirrorFrontFacingCamera;
-(char)horizontallyMirrorRearFacingCamera;
-(int)frameRate;
-(void)setFrameRate:(int)arg1 ;
-(void)setDelegate:(id<GPUImageVideoCameraDelegate>)arg1 ;
-(void)dealloc;
-(id)init;
-(id<GPUImageVideoCameraDelegate>)delegate;
-(void)captureOutput:(id)arg1 didOutputSampleBuffer:(opaqueCMSampleBufferRef)arg2 fromConnection:(id)arg3 ;
-(int)cameraPosition;
-(AVCaptureSession *)captureSession;
@end

